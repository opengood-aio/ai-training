{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyN2fBThgo8wJQn6Xf6V6crC"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "### Layout\n",
    "\n",
    "* Images:\n",
    "\t* Dog\n",
    "    * Cat\n",
    "* 1000s of images\n",
    "\t* Training set\n",
    "\t    * 4000 images each for dogs and cats\n",
    "    * Test set\n",
    "        * 1000 images each for dogs and cat\n",
    "\n",
    "### Goals\n",
    "\n",
    "* Build a CNN model to classify images for a dog or cat"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": "## Import Libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sCV30xyVhFbE",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:53.917168Z",
     "start_time": "2025-09-01T22:17:53.913836Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FIleuCAjoFD8",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:53.934234Z",
     "start_time": "2025-09-01T22:17:53.931858Z"
    }
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.20.0'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": "## Data Preprocessing"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": "### Preprocessing Training Set"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Image Augmentation\n",
    "\n",
    "* Transformations will be applied to images only in the training set\n",
    "    * This is to avoid over fitting\n",
    "    * Otherwise, there will be a huge difference in accuracy of the training and test sets:\n",
    "        * Close to $98\\%$ accuracy on the training set\n",
    "        * Much lower accuracy on the test set\n",
    "* Geometric transformations are applied to the training set images:\n",
    "    * For example, zoom, rotations, etc. on the images\n",
    "    * First, transvections to shift pixels\n",
    "    * Next, rotations with horizontal flips and zoom-in-and-out\n",
    "* These transformations are called **image augmentation**\n",
    "* The goal is to augment the diversity of the training set images"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Image Generation\n",
    "\n",
    "* The `ImageDataGenerator` class from the `preprocessing.image` module of the Keras library is used to generate images and perform image augmentation\n",
    "    * Parameters\n",
    "        * `rescale` applies feature scaling to each pixel\n",
    "            * Each pixel has a value between $0$ and $255$\n",
    "            * Each pixel value is divided by $255$\n",
    "            * This will normalize the pixel values in images\n",
    "        * `shear_range` randomly applies a range of shear transformations that shift pixels by a specified position to images\n",
    "        * `zoom_range` randomly applies a range of zooming to images\n",
    "        * `horizontal_flip` indicates a value to flip images horizontally\n",
    "* The `train_datagen` variable defines an instance of the `ImageDataGenerator` class\n",
    "* The training dataset will be imported from the dataset directory containing the directory of training set images\n",
    "    * The `flow_from_directory` method on the `ImageDataGenerator` class recursively loads images from a specified directory\n",
    "        * Parameters\n",
    "            * `directory` is the root directory of images to process\n",
    "            * `target_size` performs image resizing by specifying the target pixel size of the images\n",
    "                * This makes the image processing less computationally intensive\n",
    "            * `batch_size` indicates the number of images to process per batch\n",
    "            * `class_mode` specifies the classification mode: `binary` or `categorical`\n",
    "* The `training_set` variable is the training set of the images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0koUcJMJpEBD",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:53.947755Z",
     "start_time": "2025-09-01T22:17:53.945875Z"
    }
   },
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.116375Z",
     "start_time": "2025-09-01T22:17:53.959330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "    directory='dataset/training_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": "### Preprocessing Test Set"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* Image augmentation is not applied to test set images so those parameters are omitted"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SH4WzfOhpKc3",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.166669Z",
     "start_time": "2025-09-01T22:17:54.123299Z"
    }
   },
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    directory='dataset/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": "## Build CNN"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": "### Initialize CNN"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The `Sequential` class is from the `models` module of the Keras library and allows one to construct a neural network made of a sequence of layers\n",
    "* The `cnn` variable is an object instance of the `Sequential` class"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SAUt4UMPlhLS",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.178708Z",
     "start_time": "2025-09-01T22:17:54.176541Z"
    }
   },
   "source": "cnn = tf.keras.models.Sequential()",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": "### Step 1 - Convolution"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The `Conv2D` class is from the `layers` module of the Keras library and creates a convolutional layer\n",
    "    * Parameters\n",
    "        * `filters` is the number of feature detectors used to perform convolution\n",
    "        * `kernel_size` is the size of the array (matrices as row and columns) for a feature detector\n",
    "        * `strides` is the number of pixels to move a feature detector across and up/down an image. Default value of $1$ will be used.\n",
    "        * `activation` is the activation function to apply after convolution\n",
    "        * `input_shape` is the dimensions of an input image in the RGB 3 dimensions of color:\n",
    "            * `width` = $64$ pixels\n",
    "            * `height` = $64$ pixels\n",
    "            * `colors` = $3$ indicates colored images. $0$ = black and $1$ = white."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPzPrMckl-hV",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.198171Z",
     "start_time": "2025-09-01T22:17:54.192409Z"
    }
   },
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(64, 64, 3)\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The `MaxPoolConv2D` class is from the `layers` module of the Keras library and creates a pooling layer using max pooling\n",
    "    * Parameters\n",
    "        * `pool_size` is the size of the array (matrices as row and columns) of the pool window (frame)\n",
    "        * `strides` is the number of pixels to move the pool window across and up/down an image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ncpqPl69mOac",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.204860Z",
     "start_time": "2025-09-01T22:17:54.201588Z"
    }
   },
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=(2, 2)\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": "### Add 2nd Convolutional Layer"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* The `input_shape` parameter is omitted because is the shape is only defined on the first convolutional layer in the CNN"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i_-FZjn_m8gk",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.213867Z",
     "start_time": "2025-09-01T22:17:54.208414Z"
    }
   },
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.223363Z",
     "start_time": "2025-09-01T22:17:54.220004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=(2, 2)\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The `Flatten` class is from the `layers` module of the Keras library and creates a flattening layer\n",
    "    * No parameters are required for an instance of this class"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.229859Z",
     "start_time": "2025-09-01T22:17:54.226442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.Flatten()\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The `Dense` class is from the `layers` module of the Keras library and allows one to add a fully connected layer to an ANN\n",
    "    * An object instance of this class is used to construct a connected layer\n",
    "    * Parameters\n",
    "        * `units` defines the number of hidden neurons in a hidden layer\n",
    "            * $128$ neurons are used to achieve a higher level of accuracy\n",
    "        * `activation` defines the activation function\n",
    "            * Rectifier activation function (`relu`) will be used for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8GtmUlLd26Nq",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.242346Z",
     "start_time": "2025-09-01T22:17:54.235083Z"
    }
   },
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=128,\n",
    "        activation='relu'\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* The same `Dense` class is used to construct the output layer except it:\n",
    "    * Has $1$ neuron\n",
    "        * Since there is only $1$ dependent variable\n",
    "    * Has Sigmoid activation function\n",
    "        * Used when making predictions that are binary for classification"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1p_Zj1Mc3Ko_",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.253701Z",
     "start_time": "2025-09-01T22:17:54.247172Z"
    }
   },
   "source": [
    "cnn.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1,\n",
    "        activation='sigmoid'\n",
    "    )\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": "## Training CNN"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": "### Compile CNN"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NALksrNQpUlJ",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.262550Z",
     "start_time": "2025-09-01T22:17:54.261177Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": "### Train CNN on Training Set and Evaluate on Test Set"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XUj1W4PJptta",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.281280Z",
     "start_time": "2025-09-01T22:17:54.279704Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": "## Make Predictions"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Make Single Prediction"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gsSiWEJY1BPB",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.298545Z",
     "start_time": "2025-09-01T22:17:54.297086Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ED9KB3I54c1i",
    "ExecuteTime": {
     "end_time": "2025-09-01T22:17:54.323544Z",
     "start_time": "2025-09-01T22:17:54.321852Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
